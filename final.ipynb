import pandas as pd
import numpy as np
import re
import os
import torch
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
from torch.nn import BCEWithLogitsLoss
from sklearn.metrics import average_precision_score # For standard AP score

# --- Configuration ---
TRAIN_FILE = '/kaggle/input/map-charting-student-math-misunderstandings/train.csv'
TEST_FILE = '/kaggle/input/map-charting-student-math-misunderstandings/test.csv'
MODEL_NAME = '/kaggle/input/map-deberta-v2-trained-model/deberta_results/checkpoint-6195' # High-performance model
MAX_LEN = 256  # Max length for the combined input text
NUM_EPOCHS = 3
LR = 2e-5




# --- 1. Data Preparation and Feature Engineering ---

def clean_text(text):
    """Basic text cleaning: lowercase and remove non-alphanumeric characters."""
    if isinstance(text, str):
        # Decode common LaTeX/unicode, clean, and strip excess whitespace
        text = text.lower()
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    return ""

def format_input(row):
    """
    Combines all relevant context into a single input string for the model.
    This mimics the successful strategy of providing full context.
    """
    # Using a clear separator for the model
    return (
        f"Question: {clean_text(row['QuestionText'])} \n"
        f"Answer: {clean_text(row['MC_Answer'])} \n"
        f"Explanation: {clean_text(row['StudentExplanation'])}"
    )

def load_data(path, is_training=True):
    """Loads and prepares data, including feature engineering."""
    try:
        df = pd.read_csv(path)
    except FileNotFoundError:
        print(f"Error: File not found at {path}")
        return None

    # Rename columns for consistency
    df.rename(columns={'StudentExplanation': 'StudentExplanation', 
                      'Misconception': 'misconception_name'}, inplace=True)
    
    # Generate the rich input feature
    df['input_text'] = df.apply(format_input, axis=1)
    
    if is_training:
        # Create the combined target label
        df['target_label'] = df['Category'].astype(str) + ':' + df['misconception_name'].fillna('NA').astype(str)
        # Group to get a list of all targets per student response (Multi-Label)
        df_responses = df.groupby('row_id')['target_label'].apply(list).reset_index(name='labels')
        
        # Merge back the unique input text for each row_id
        df_responses = df_responses.merge(df[['row_id', 'input_text']].drop_duplicates(subset=['row_id']), on='row_id')
        
        return df_responses
    
    return df



# --- 2. Custom Dataset and Model Utils ---

class MisconceptionDataset(Dataset):
    """PyTorch Dataset compatible with Hugging Face Trainer."""
    def _init_(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def _getitem_(self, idx):
        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}
        
        if self.labels is not None:
            # Use float for BCEWithLogitsLoss
            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)
            
        return item

    def _len_(self):
        return len(self.encodings['input_ids'])

# MAP@K is essential for local evaluation/monitoring
def map_at_k(y_true, y_pred_proba, k=3):
    """Calculates Mean Average Precision at K (MAP@K) for multi-label classification."""
    avg_precisions = []
    # Sort predictions (high to low) and get the indices
    sorted_pred_indices = np.argsort(y_pred_proba, axis=1)[:, ::-1] 
    
    for i in range(y_true.shape[0]):
        # Get the indices of the true positive labels
        true_labels = np.where(y_true[i] == 1)[0]
        if len(true_labels) == 0: continue
        
        top_k_pred_indices = sorted_pred_indices[i, :k]
        running_correct = 0
        total_precision = 0
        remaining_true = set(true_labels)
        
        for rank, pred_idx in enumerate(top_k_pred_indices, 1):
            if pred_idx in remaining_true:
                running_correct += 1
                total_precision += (running_correct / rank)
                remaining_true.remove(pred_idx)
                if not remaining_true: break
        
        if running_correct > 0:
            avg_precisions.append(total_precision / len(true_labels))

    return np.mean(avg_precisions) if avg_precisions else 0.0

def compute_metrics(p, mlb_classes):
    """Custom metric function for Trainer to calculate MAP@3."""
    logits = p.predictions
    # Sigmoid to convert logits to probabilities
    probabilities = torch.sigmoid(torch.tensor(logits)).numpy()
    y_true = p.label_ids
    
    # Calculate MAP@3 for the competition
    map3_score = map_at_k(y_true, probabilities, k=3)
    
    # Calculate standard macro Average Precision for comparison
    macro_ap = average_precision_score(y_true, probabilities, average='macro')
    
    return {'map3_score': map3_score, 'macro_ap': macro_ap}

# --- 3. Pipeline Execution ---

def run_trainer_pipeline():
    # --- Load and Prepare Data ---
    df_responses = load_data(TRAIN_FILE, is_training=True)
    if df_responses is None: return

    # --- Multi-Label Encoding ---
    mlb = MultiLabelBinarizer()
    Y_labels = mlb.fit_transform(df_responses['labels'])
    num_labels = len(mlb.classes_)

    # --- Split Data (Training is easier without stratification here) ---
    X_train, X_val, Y_train, Y_val = train_test_split(
        df_responses['input_text'].tolist(), Y_labels, test_size=0.1, random_state=42
    )

    # --- Tokenization ---
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)

    train_encodings = tokenizer(
        X_train, truncation=True, padding='max_length', max_length=MAX_LEN, return_tensors='pt'
    )
    val_encodings = tokenizer(
        X_val, truncation=True, padding='max_length', max_length=MAX_LEN, return_tensors='pt'
    )

    # --- Dataset Creation ---
    train_dataset = MisconceptionDataset(train_encodings, Y_train)
    val_dataset = MisconceptionDataset(val_encodings, Y_val)

    # --- Model Loading and Configuration ---
    model = AutoModelForSequenceClassification.from_pretrained(
        MODEL_NAME,
        num_labels=num_labels,
        # Set problem type for multi-label classification (uses Sigmoid)
        problem_type="multi_label_classification",
        # Custom loss function to handle multi-label (BCEWithLogitsLoss)
        # loss_function=BCEWithLogitsLoss() # Removed as it's not a valid argument
    )

    # --- Training Arguments ---
    training_args = TrainingArguments(
        output_dir='./deberta_results',
        num_train_epochs=NUM_EPOCHS,
        per_device_train_batch_size=16, # Increased batch size for efficiency
        per_device_eval_batch_size=16,
        warmup_ratio=0.1, # Use 10% of steps for learning rate warmup
        weight_decay=0.01,
        learning_rate=LR,
        logging_steps=50,
        eval_strategy="epoch", # Evaluate at the end of each epoch
        save_strategy="epoch",
        load_best_model_at_end=True, # Load the model with the best validation score
        metric_for_best_model='map3_score',
        greater_is_better=True,
        fp16=torch.cuda.is_available(), # Use mixed precision if GPU is available
    )

    # --- Trainer Initialization and Training ---
    print(f"\n--- Starting Training DeBERTa-v3 on {torch.device('cuda' if torch.cuda.is_available() else 'cpu')} ---")

    # We wrap compute_metrics to pass the classes object to the internal function
    def wrapped_compute_metrics(p):
        return compute_metrics(p, mlb.classes_)

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        tokenizer=tokenizer,
        compute_metrics=wrapped_compute_metrics,
    )

    trainer.train()

    # --- Prediction and Submission Generation ---
    if os.path.exists(TEST_FILE):
        print("\n--- Generating Submission on Test Data ---")
        generate_submission(trainer, mlb, TEST_FILE, tokenizer)
    else:
        print(f"Test file {TEST_FILE} not found. Cannot generate submission.")


def generate_submission(trainer, mlb, test_path, tokenizer, output_filename='submission_deberta_trainer.csv'):
    """Generates the final submission file using the Hugging Face Trainer."""

    df_test = load_data(test_path, is_training=False)

    X_test = df_test['input_text'].tolist()
    test_encodings = tokenizer(
        X_test, truncation=True, padding='max_length', max_length=MAX_LEN, return_tensors='pt'
    )
    test_dataset = MisconceptionDataset(test_encodings)

    # Predict logits using the best model loaded by the Trainer
    raw_predictions = trainer.predict(test_dataset).predictions

    # Convert logits to probabilities
    probabilities = torch.sigmoid(torch.tensor(raw_predictions)).numpy()

    # Get indices of top 3 probability predictions
    # argsort[::-1] gives descending indices, [:3] takes the top 3
    top_3_indices = np.argsort(probabilities, axis=1)[:, ::-1][:, :3]

    predictions = []

    # Map the indices back to the actual class names (Category:Misconception)
    for row in top_3_indices:
        labels = [mlb.classes_[i] for i in row]
        predictions.append(' '.join(labels))

    # Create the submission DataFrame
    submission_df = pd.DataFrame({
        'row_id': df_test['row_id'],
        'Category:Misconception': predictions
    })

    submission_df.to_csv(output_filename, index=False)
    print(f"Submission file saved successfully to {output_filename}")


if _name_ == "_main_":
    run_trainer_pipeline()
