#this is the new and correct notebook
import pandas as pd
import numpy as np
import re
import os
import torch
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
from torch.nn import BCEWithLogitsLoss
from sklearn.metrics import average_precision_score # For standard AP score









###6
# --- 3. Pipeline Execution ---

def run_trainer_pipeline():
    # --- Load and Prepare Data ---
    df_responses = load_data(TRAIN_FILE, is_training=True)
    if df_responses is None: return

    # --- Multi-Label Encoding ---
    mlb = MultiLabelBinarizer()
    Y_labels = mlb.fit_transform(df_responses['labels'])
    num_labels = len(mlb.classes_)

    # --- Split Data (Training is easier without stratification here) ---
    X_train, X_val, Y_train, Y_val = train_test_split(
        df_responses['input_text'].tolist(), Y_labels, test_size=0.1, random_state=42
    )

    # --- Tokenization ---
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)

    train_encodings = tokenizer(
        X_train, truncation=True, padding='max_length', max_length=MAX_LEN, return_tensors='pt'
    )
    val_encodings = tokenizer(
        X_val, truncation=True, padding='max_length', max_length=MAX_LEN, return_tensors='pt'
    )
